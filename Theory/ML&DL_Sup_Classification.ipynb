{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **지도학습(Supervised) 알고리즘:** 분류분석\n",
    "\n",
    "- **분류분석:** `지도학습` 알고리즘 중 `분류`를 위해 사용되는 가장 `기본(Baseline) 알고리즘`\n",
    "\n",
    "> (비수학적) **\"일상 속 문제 중 여러개의 선택지 중에 정답을 고르는 문제\"**\n",
    "> - 주관식 시험문제의 숫자형 정답을 찾는 문제가 `예측문제`\n",
    "> - 객관식 시험문제의 정답을 찾는 문제가 `분류문제`\n",
    "\n",
    "> (수학적) **\"범주형 출력(`Y, 종속변수`)에 영향을 주는 입력(`X, 독립변수`)과의 관계를 정량적으로 추론/추정하여 `미래 값을 분류`하는 알고리즘\"**\n",
    "> - **예측문제:** 데이터 변수(Feature, Variable)들을 사용하여 `연속적인(Continuous) 값을 예측`\n",
    "> - **분류문제:** 데이터 변수(Feature, Variable)들을 사용하여 `특정 분류값을 예측`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/Advanced/ML_Type_Application_Upgrade.png' width='700'></center>  \n",
    "<center><img src='Image/Advanced/ML_Type_Category.png' width='700'></center>\n",
    "\n",
    "---\n",
    "\n",
    "| Regression Algorithms | Instance-based Algorithms | Regularization Algorithms | Decision Tree Algorithms | Bayesian Algorithms | Artificial Neural Network Algorithms |\n",
    "|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| <img src='Image/Advanced/Regression-Algorithms.png' width='150'> | <img src='Image/Advanced/Instance-based-Algorithms.png' width='150'> | <img src='Image/Advanced/Regularization-Algorithms.png' width='150'> | <img src='Image/Advanced/Decision-Tree-Algorithms.png' width='150'> | <img src='Image/Advanced/Bayesian-Algorithms.png' width='150'> | <img src='Image/Advanced/Artificial-Neural-Network-Algorithms.png' width='150'> |\n",
    "| Ordinary Least Squares Regression (OLSR) | k-Nearest Neighbor (kNN) | Ridge Regression | Classification and Regression Tree (CART) | Naive Bayes | Perceptron |\n",
    "| Linear Regression | Learning Vector Quantization (LVQ) | Least Absolute Shrinkage and Selection Operator (LASSO) | Iterative Dichotomiser 3 (ID3) | Gaussian Naive Bayes | Back-Propagation |\n",
    "| Logistic Regression | Self-Organizing Map (SOM) | Elastic Net | C4.5 and C5.0 (different versions of a powerful approach) | Multinomial Naive Bayes | Hopfield Network |\n",
    "| Stepwise Regression | Locally Weighted Learning (LWL) | Least-Angle Regression (LARS) | Chi-squared Automatic Interaction Detection (CHAID) | Averaged One-Dependence Estimators (AODE) | Radial Basis Function Network (RBFN) |\n",
    "| Multivariate Adaptive Regression Splines (MARS) | - | - | Decision Stump | Bayesian Belief Network (BBN) | - |\n",
    "| Locally Estimated Scatterplot Smoothing (LOESS) | - | - | M5 | Bayesian Network (BN) | - |\n",
    "| - | - | - | Conditional Decision Trees | - | - |\n",
    "\n",
    "- **Target Algorithm:**\n",
    "> - `Logistic Regression`\n",
    "> - Ordinal Regression\n",
    "> - Cox Regression\n",
    "> - <span style=\"color:red\">**Naïve Bayes**</span>\n",
    "> - Stochastic Gradient Descent\n",
    "> - K-Nearest Neighbours\n",
    "> - Decision Tree\n",
    "> - Random Forest\n",
    "> - <span style=\"color:red\">**Support Vector Machine**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **함수세팅 및 추정 방향(Modeling):** Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류문제에 회귀분석 사용시 한계 및 대응"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 회귀문제에 회귀분석은 적절**\n",
    "\n",
    "> **\"연속형 종속변수 예시\"**\n",
    ">\n",
    "> <center><img src='Image/Advanced/Example_LinearRegression.png' width='600'></center>\n",
    "\n",
    "**2) 분류문제에 회귀분석은 부적절**\n",
    "\n",
    "> **\"범주형 종속변수 예시\"**\n",
    "> - Outlier가 존재하면 Linear Regression의 추정은 왜곡을 발생시킴\n",
    ">\n",
    "> <center><img src='Image/Advanced/Example_LinearRegression_Limit.png' width='600'></center>\n",
    "\n",
    "**3) 분류문제 해결을 위한 대응:**\n",
    "\n",
    "> **회귀분석:** `연속형 종속변수 Y`의 값을 추론\n",
    "> - 혈압의 경우 값 자체로 의미가 있지만 `암발생은 발생(1)과 미발생(0) 사이의 중간값 무의미`\n",
    "> - 회귀분석으로 범주형 종속변수를 추론하면 범위가 맞지 않아 `암발생 여부의 해석이 왜곡`\n",
    ">> - 나이가 많아지면 무조건 암이 걸리거나 나이가 어리면 무조건 암이 걸리지 않는 왜곡 발생\n",
    "> - 범주형 Y일 경우 회귀분석의 한계 존재하며 이를 해결하기 위한 접근 필요\n",
    "\n",
    "> **분류분석:** `범주형(범주/카테고리/클래스/라벨) 종속변수 Y`의 분류를 추론\n",
    "> - **시그모이드 함수(Sigmoid Function) 적용:** 연속형 Y를 `0과 1사이의 값으로 변환`하면서 분류에 맞게 `S자 형태로 적합(Fitting)`하는 함수\n",
    ">\n",
    "> <center><img src='Image/Advanced/Example_LogisticRegression.png' width='600'></center>\n",
    "\n",
    "**4) 분류분석 종류:** Y 카테고리 갯수와 방향에 따라 `Binary/Multi-class/Multi-label`로 구분\n",
    "> - **Binary Classification:** 데이터가 `2개의 카테고리` 중 `어떤 것`인지 추론하는 문제 (ex. 성별 추론 / 스팸메일 추론)\n",
    "> - **Multi-class classification:** 데이터가 `2개 이상의 카테고리` 중 `어떤 것`인지 추론하는 문제 (ex. 사진으로 동물 이름 추론)\n",
    "> - **Multi-label classification:** 데이터가 `2개 이상의 카테고리` 중 `어떠한 것들`인지 추론하는 문제 (ex. 뉴스기사는 스포츠/사람/지역 관련임을 추론)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류문제 해결을 위한 가설 및 비용함수\n",
    "\n",
    "> **\"선형회귀분석을 포함하여 머신러닝과 딥러닝 등의 `모든 알고리즘은 큰 틀에서 작동방식이 동일`\"**\n",
    ">\n",
    "> **\"머신러닝과 딥러닝의 작동방식을 이해하기 위해 가장 기초 예측 알고리즘인 `선형회귀분석(Linear Regression)` 작동방식부터\"**\n",
    ">\n",
    "> **\"`선형회귀분석`을 포함한 대부분의 알고리즘은 큰 틀에서 `3가지 도구`를 사용하여 작동\"**\n",
    ">\n",
    "> **1)** `방정식(Equation) = 함수(Function) = 가설(Hypothesis)`\n",
    ">\n",
    "> **2)** `비용함수(Cost Function)`\n",
    ">\n",
    "> **3)** `옵티마이저(Optimizer)`\n",
    "\n",
    "---\n",
    "\n",
    "**1-1) 알고리즘 함수세팅:** 분류문제를 푸는 대표적인 알고리즘 `Logistic Regression`\n",
    "\n",
    "- `범주형 종속변수`의 적합/추정하기 위한 `변환과정` 필요\n",
    "- `Logistic/Sigmoid Function`를 사용하여 `곡선(S-curve) 형태로 변환`\n",
    "\n",
    "<center><img src='Image/Advanced/Linear_Logistic.png' width='600'></center>\n",
    "\n",
    "> **(1) 회귀분석 추정:**\n",
    ">\n",
    ">\\begin{align*}\n",
    "Y \\approx \\hat{Y} &= f(X_1, X_2, ..., X_k) \\\\\n",
    "&= w_0 + w_1X_1 + w_2X_2 + \\cdots + w_kX_k \\\\\n",
    "&= XW\n",
    "\\end{align*}\n",
    ">\n",
    "> **(2) 시그모이드 변환(Logistic/Sigmoid Transformation):** `Binary Classification` 반영하는 `곡선 형태`로 변경\n",
    ">\n",
    ">\\begin{align*}\n",
    "Pr(\\hat{Y}) &= \\dfrac{1}{1+exp(-\\hat{Y})} \\\\ \n",
    "&= \\dfrac{1}{1+exp(-XW)} \\\\\n",
    "&= \\dfrac{exp(XW)}{1+exp(XW)}\n",
    "\\end{align*}\n",
    ">\n",
    "> **(3) 로짓 변환(Logit Transformation):** `X`의 선형관계 형태로 변환하여 `변수들`로 `Y=1`인 확률 추정\n",
    ">\n",
    ">\\begin{align*}\n",
    "Pr(\\hat{Y}) \\left( 1 + exp(XW) \\right) &= exp(XW) \\\\\n",
    "Pr(\\hat{Y}) &= \\left( 1 - Pr(\\hat{Y}) \\right) exp(XW) \\\\\n",
    "\\text{Odds(ratio):} \\left( \\dfrac{Pr(\\hat{Y})}{1 - Pr(\\hat{Y})} \\right) &= exp(XW) \\\\\n",
    "\\text{Logit(log-odds): } log \\left( \\dfrac{Pr(\\hat{Y})}{1 - Pr(\\hat{Y})} \\right) &= XW = w_0 + w_1X_1 + w_2X_2 + \\cdots + w_kX_k \\\\\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "\n",
    "**1-2) 추정 결과 해석:**\n",
    "\n",
    "> **(1) 해석 방향:** $\\hat{Logit}$과 $\\hat{Odds}$ `변환`으로 가능\n",
    "> $$\n",
    "\\begin{align*}\n",
    "\\text{Logit: } log \\left( \\dfrac{Pr(Y)}{1 - Pr(Y)} \\right) &= X\\hat{W} = \\hat{w}_0 + \\hat{w}_1X_1 + \\hat{w}_2X_2 + \\cdots + \\hat{w}_kX_k \\\\\n",
    "\\text{Odds: } \\left( \\dfrac{Pr(Y)}{1 - Pr(Y)} \\right) &= exp(X\\hat{W}) = exp(\\hat{w}_0 + \\hat{w}_1X_1 + \\hat{w}_2X_2 + \\cdots + \\hat{w}_kX_k) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    ">\n",
    "> **(2) 회귀분석과 달리 `Y`의 로짓변환 값을 `X`의 선형관계로 추정하기 때문에, 해석시 `Odds`로 변환해서 해석해야 하므로 `주의`**\n",
    ">\n",
    "> \\begin{align*}\n",
    "\\left( \\dfrac{Pr(Y)}{1 - Pr(Y)} \\right) = exp(0.01 + 0.8 X_1)\n",
    "\\end{align*}\n",
    ">\n",
    "> - **선형회귀분석:** $X_1$이 1만큼 증가하면 $Y$는 $w_1$만큼 증가\n",
    ">\n",
    ">> : $X_1$이 `1`만큼 증가하면 $Y$는 `0.8`만큼 증가\n",
    ">\n",
    "> - **로지스틱회귀분석:** $X_1$이 1만큼 증가하면 $\\left( \\dfrac{Pr(\\hat{Y})}{1 - Pr(\\hat{Y})} \\right)$ 범주변화는 $exp(w_1)$만큼 증가\n",
    ">\n",
    ">> : $X_1$이 `1`만큼 증가하면 암에 걸리지 않을 확률보다 암에 걸릴 확률이 $exp(0.8)$ = `2.23`배 더 높음\n",
    ">\n",
    "> **(3) Y 확률 예측:** `추정된 계수`의 함수를 `로지스틱 변환`으로 출력\n",
    ">\n",
    "> \\begin{align*}\n",
    "Pr(\\hat{Y}) &= \\dfrac{1}{1+exp(-X\\hat{W})} = \\dfrac{exp(X\\hat{W})}{1+exp(X\\hat{W})}\n",
    "\\end{align*}\n",
    ">\n",
    "> **(4) 분류 의사결정:** 기본 임계값은 `0.5`로 Y 확률 예측 값이 `0.5 이상이면 1`, `0.5 미만이면 0`으로 분류\n",
    ">\n",
    "> \\begin{align*}\n",
    "\\hat{Y} = \\begin{cases} 1 ~~~~ \\text{if } ~~~ Pr(\\hat{Y}) >= 0.5 \\\\ 0 ~~~~ \\text{if } ~~~ Pr(\\hat{Y}) < 0.5 \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "\n",
    "**2) 함수 추정을 위한 비용함수:** 나의 주장 기반 알고리즘의 `분류값`($Pr(\\hat{Y})$)과 `실제 데이터`($Y$)의 차이를 평가하는 함수\n",
    "\n",
    "- **이슈: `잔차`를 사용하는 Linear Regression 비용함수 적용 어려움**    \n",
    "\n",
    "> (1) 분류문제에서는 $\\hat{Y}$를 사용한 `잔차(에러)계산이 무의미`   \n",
    ">\n",
    "> (2) 잔차($Y - \\hat{Y}$)를 `시그모이드 및 로짓 변환`을 하면 Non-convex 형태가 되서 `최소값(Global Minimum) 추정 어려움`    \n",
    ">\n",
    "> (3) 정확한 `수학적 방정식 기반` 계수추정 어렵기에 `확률론적 접근 필요`    \n",
    ">\n",
    "> <center><img src='Image/Advanced/Cost_Comparison.png' width='600'></center>\n",
    "\n",
    "- **방향:** 회귀문제와 달리 `새로운 비용함수`가 필요\n",
    "\n",
    "> - Y를 `잘` 분류하면 `cost=0`으로 그렇지 않으면 cost=$\\infty$가 되는 방향\n",
    ">> - (빨간선) 실제값이 `1`일때 예측값이 `1`이면 Cost는 `0`\n",
    ">> - (빨간선) 실제값이 `1`일때 예측값이 `0`이면 Cost는 `무한대`\n",
    ">\n",
    "> \\begin{align*}\n",
    "\\text{Cost} = \\begin{cases} -log(Pr(\\hat{Y})) ~~~~ & \\text{in the case of } ~~~ Y = 1 \\\\ -log(1-Pr(\\hat{Y})) ~~~~ & \\text{in the case of } ~~~ Y = 0 \\end{cases}\n",
    "\\end{align*}\n",
    "> <center><img src='Image/Advanced/Cost_Logistic.png' width='600'></center>\n",
    "\n",
    "- **Cross Entropy 등장:** Y가 0과 1인 경우의 `Cost를 결합`하여 하나의 식으로 표현\n",
    "\n",
    "> - 로지스틱 알고리즘은 `비용함수`로 `Cross Entropy`를 사용하고 `최소로 하는 계수/가중치 추정`\n",
    "> - `Y=0`인 경우 `파란부분`만 남고 `Y=1`인 경우 `빨간부분`만 남아 `Class별`로 독립적으로 작동\n",
    "> - 분류문제의 `Cost 함수는 다양`하고 많지만 통계학적으로 `Cross Entropy`는 계수 추정에 `효율적`인 편\n",
    "> - `Convex 형태`이기 때문에 `Global Minimum`을 찾기가 용이함\n",
    "> - 추정된 계수/가중치($\\hat{w}$)로 방정식을 만들어 Y=1인 `분류확률` 계산 가능\n",
    ">\n",
    ">\\begin{align*}\n",
    "\\text{Cost} &= \\sum_{i=1}^{m} \\left[ - \\color{red}{\\hat{Y}_{i} log (Pr(\\hat{Y}_{i}))} - \\color{blue}{(1-\\hat{Y}_{i}) log (1-Pr(\\hat{Y}_{i}))} \\right] \\\\\n",
    "\\hat{W} &= \\underset{W}{\\arg\\min} \\sum_{i=1}^{m} \\left[\\text{Cost} \\right] \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class 분류문제\n",
    "\n",
    "- **Binary vs. Multi-class:**\n",
    "\n",
    "<center><img src='Image/Advanced/Classification_BinaryMuticlass.png' width='600'></center>\n",
    "\n",
    "- **방향:** `N개`의 Class(Category)가 있는 문제는 `N개의 Binary Classification`으로 바꾸어 해결\n",
    "\n",
    "> (1) 세모가 Positive일때 Y가 세모에 속할 확률\n",
    ">\n",
    "> (2) 네모가 Positive일때 Y가 네모에 속할 확률\n",
    ">\n",
    "> (3) 엑스가 Positive일때 Y가 엑스에 속할 확률\n",
    ">\n",
    "> **\"데이터가 주어지면 3개의 경우를 모두 적용하여 최대 확률을 갖는 Class로 추정\"**\n",
    ">\n",
    "> <center><img src='Image/Advanced/Classification_Multiclass.png' width='600'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 서포트 벡터 머신(Support Vector Machine, SVM)\n",
    "\n",
    "**1) 알고리즘 함수세팅:** `서로 다른 집단`간 `상대적인 거리`를 `최대화`하는 기준면을 파악하여 `분류`\n",
    "\n",
    "- `Regression, Classification` 분석에 사용가능하며, `분류`의 대표적 기법\n",
    "- 이론 기반 알고리즘으로 `결과해석 용이`하고 `스몰데이터`에도 효과적\n",
    "- `빅데이터`의 경우 과적합 경우가 적으며 `인공신경망` 수준의 성능\n",
    "- `Separating Hyperplane`을 기준으로 클래스/카테고리/레이블을 분류하는 방식\n",
    "\n",
    "> - **Separating Hyperplane:** 데이터 클래스들 사이의 `거리/차이(Margin)`를 최대화하는 `경계(Plane)`를 말하며 `결정경계(Decision Boundary)`라고도 함\n",
    "> - **Support Vector:** Decision Boundary 기준으로 `가장 가까운 샘플/벡터`\n",
    ">\n",
    "> <center><img src='Image/Expert/Advanced_SVM_Words.png' width='500'>(https://techblog-history-younghunjo1.tistory.com/78)</center>\n",
    ">\n",
    "> - `Support Vector`만 찾아내여 결정경계가 정의되기 때문에 `다른 데이터 샘플 무시할 수 있어서 속도가 빠름`\n",
    "\n",
    "- **초평면(Hyperplane):** \n",
    "\n",
    "> - `2차원`에선 결정경계가 `1차원 직선`이고, `3차원`에선 결정경계가 `2차원 평면`이라고 하면, 차원이 증가될 경우의 결정경계 표현을 `초평면`이라고 총칭\n",
    ">\n",
    "> <center><img src='Image/Expert/Advanced_SVM_HyperplaneComparison.png' width='600'>(https://hleecaster.com/ml-svm-concept/)</center>\n",
    "\n",
    "---\n",
    "\n",
    "**2) 거리/차이(Margin)에 따른 결과 차이:** 결정경계와 가장 가까운 샘플 사이 거리를 `마진(Margin)`\n",
    "\n",
    "- **하드마진(Hard Margin):** `아웃라이어를 허용하지 않도록` 엄격하게 모델링 하는 것으로 `마진이 작아지고` 모든 데이터를 놓치지 않고 학습하려는 `과대적합` 가능성\n",
    "- **소프트마진(Soft Margin):** `아웃라이어를 어느정도 허용`하도록 다소 너그럽게 모델링 하는 것으로 `마진이 커지고` 대충 데이터를 학습하는 `과소적합` 가능\n",
    "\n",
    "<center><img src='Image/Expert/Advanced_SVM_MaxMargin.png' width='600'>(https://hleecaster.com/ml-svm-concept/)</center>\n",
    "\n",
    "- `적절한 마진`으로 `분류 성능`도 높이고 `Outlier`에 영향을 적게 받는 `Robust`한 모델링 필요\n",
    "- 마진은 `최대화`하면서 오분류(아웃라이어)는 `최소화` 하기 위한 Trade-off를 조정하기 위해 `비용함수에 규제파라미터(Regularization Parameter) 또는 패널티(Penalty) 부여`\n",
    "\n",
    "---\n",
    "\n",
    "**3) 정리 및 비선형/다중 분류:**\n",
    "\n",
    "- `결정 경계(Decision Boundary)`를 정의하고, 분류되지 않은 점을 해당 결정 경계와 `비교해서 분류`\n",
    "\n",
    "- 최적화를 위해 `여러개의 조합`을 테스트 하기에 상대적으로 `학습속도는 느릴 수 있음`\n",
    "\n",
    "- **Kernel SVM:** 기본적으론 `선형 직선` 기준으로 분류하지만, `비선형 방식`으로도 SVM 사용 가능\n",
    "\n",
    "> - **커널(Kernel):** 원데이터를 `더 높은 차원으로 변환`하는 알고리즘\n",
    "> - 선형 분리가 어려운 데이터에는 `비선형 접근`인 `커널(Kernel)` 사용\n",
    "> - `Kernel SVM`이 등장하게 되었는데, 차원변환 방식에 따라 다양한 `Kernel` 존재\n",
    ">\n",
    "> <center><img src='Image/Expert/Advanced_SVM_Hyperplane.png' width='600'>(https://www.hackerearth.com/blog/developers/simple-tutorial-svm-parameter-tuning-python-r/)</center>\n",
    "\n",
    "- **Structural SVM:** `레이블이 여러개`인 경우 사용하는 `분류` 알고리즘\n",
    "\n",
    "---\n",
    "**SVR**\n",
    "> <center><img src='Image/Expert/Difference-of-SVM-and-SVR-diagram.png' width='600'></center>\n",
    "\n",
    "---\n",
    "\n",
    "**4) 사용방법:**\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC, SVR\n",
    "```\n",
    "\n",
    "```python\n",
    "# 학습 및 예측\n",
    "model_svm = SVC(kernel='linear', random_state=123)\n",
    "model_svm.fit(X_train, Y_train)\n",
    "Y_trpred = model_svm.predict(X_train)\n",
    "Y_tepred = model_svm.predict(X_test)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **'<연습1>'** - Stock Price Predictor.ipynb\n",
    "\n",
    "#### Linear Regression & SVM(SVR) 이용하여 일일 종가 예측하는 모델 연습\n",
    "#### 어차피 이거로 돈 못 버니까 큰 기대는 하지 마시고 어떻게 머신러닝 모델을 이용하고 어떤 걸 쓰는게 더 좋은가 느껴보는게 더 좋을듯\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c719e123d9f928ac52be215099cb039213d76cae257ca45f86a463b29cea7241"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
