{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **지도학습(Supervised) 알고리즘:** 회귀분석\n",
    "\n",
    "- **회귀분석:** `지도학습` 알고리즘 중 `예측`을 위해 사용되는 가장 `기본(Baseline) 알고리즘`\n",
    "\n",
    "> **\"연속형 출력(`Y, 종속변수`)에 영향을 주는 입력(`X, 독립변수`)과의 관계를 정량적으로 추론/추정하여 `미래 값을 예측`하는 알고리즘\"**\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='Image/Advanced/ML_Type_Application_Upgrade.png' width='700'></center>  \n",
    "<center><img src='Image/Advanced/ML_Type_Category.png' width='700'></center>\n",
    "\n",
    "---\n",
    "\n",
    "| Regression Algorithms | Instance-based Algorithms | Regularization Algorithms | Decision Tree Algorithms | Bayesian Algorithms | Artificial Neural Network Algorithms |\n",
    "|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| <img src='Image/Advanced/Regression-Algorithms.png' width='150'> | <img src='Image/Advanced/Instance-based-Algorithms.png' width='150'> | <img src='Image/Advanced/Regularization-Algorithms.png' width='150'> | <img src='Image/Advanced/Decision-Tree-Algorithms.png' width='150'> | <img src='Image/Advanced/Bayesian-Algorithms.png' width='150'> | <img src='Image/Advanced/Artificial-Neural-Network-Algorithms.png' width='150'> |\n",
    "| Ordinary Least Squares Regression (OLSR) | k-Nearest Neighbor (kNN) | Ridge Regression | Classification and Regression Tree (CART) | Naive Bayes | Perceptron |\n",
    "| Linear Regression | Learning Vector Quantization (LVQ) | Least Absolute Shrinkage and Selection Operator (LASSO) | Iterative Dichotomiser 3 (ID3) | Gaussian Naive Bayes | Back-Propagation |\n",
    "| Logistic Regression | Self-Organizing Map (SOM) | Elastic Net | C4.5 and C5.0 (different versions of a powerful approach) | Multinomial Naive Bayes | Hopfield Network |\n",
    "| Stepwise Regression | Locally Weighted Learning (LWL) | Least-Angle Regression (LARS) | Chi-squared Automatic Interaction Detection (CHAID) | Averaged One-Dependence Estimators (AODE) | Radial Basis Function Network (RBFN) |\n",
    "| Multivariate Adaptive Regression Splines (MARS) | - | - | Decision Stump | Bayesian Belief Network (BBN) | - |\n",
    "| Locally Estimated Scatterplot Smoothing (LOESS) | - | - | M5 | Bayesian Network (BN) | - |\n",
    "| - | - | - | Conditional Decision Trees | - | - |\n",
    "\n",
    "- **Target Algorithm:**\n",
    "> - `Linear Regression` (Simple/Multiple/Multivariate)\n",
    "> - Polynomial Regression\n",
    "> - Stepwise Regression\n",
    "> - Ridge Regression\n",
    "> - Lasso Regression\n",
    "> - ElasticNet Regression\n",
    "> - Bayesian Linear Regression\n",
    "> - Quantile Regression\n",
    "> - Decision Tree Regression\n",
    "> - Random Forest Regression\n",
    "> - Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀문제 목적별 알고리즘 종류\n",
    "\n",
    "- **변수 세팅에 따른 분류:**\n",
    "\n",
    "<center><img src='Image/Expert/Regression-Algorithms-Tree1.png' width='900'></center> \n",
    "\n",
    "---\n",
    "\n",
    "- **해결 문제에 따른 분류:**\n",
    "\n",
    "<center><img src='Image/Expert/Regression-Algorithms-Tree2.png' width='900'></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀분석 작동방식으로 머신러닝 이해\n",
    "\n",
    "> **\"선형회귀분석을 포함하여 머신러닝과 딥러닝 등의 `모든 알고리즘은 큰 틀에서 작동방식이 동일`\"**\n",
    ">\n",
    "> **\"머신러닝과 딥러닝의 작동방식을 이해하기 위해 가장 기초 예측 알고리즘인 `선형회귀분석(Linear Regression)` 작동방식부터\"**\n",
    ">\n",
    "> **\"`선형회귀분석`을 포함한 대부분의 알고리즘은 큰 틀에서 `3가지 도구`를 사용하여 작동\"**\n",
    ">\n",
    "> **1)** `방정식(Equation) = 함수(Function) = 가설(Hypothesis)`\n",
    ">\n",
    "> **2)** `비용함수(Cost Function)`\n",
    ">\n",
    "> **3)** `옵티마이저(Optimizer)`\n",
    "\n",
    "---\n",
    "\n",
    "**0) 선형회귀분석(Linear Regression):** `어떤 변수 값`에 따라 `다른 변수 값이 영향`을 받는 관계성을 분석\n",
    "\n",
    "- **X(독립변수):** 다른 변수 값을 `변하게 하는 변수`\n",
    "- **Y(종속변수):** 변수 X에 의해서 종속되어 `변하는 변수`\n",
    "- **선형회귀분석:** 1개 이상의 `독립변수 X와 종속변수 Y의 관계`를 모델링\n",
    "\n",
    "| **관계로직** | **관계식** |\n",
    "|:---:|:---:|\n",
    "| `Y는 X와 같다` | $$Y = X$$ |\n",
    "| `Y는 초기값과 X들의 비율의 합과 같다` | $$Y = w_0 + w_1 X_1 + w_2 X_2 + \\cdots + w_k X_k$$ |\n",
    "\n",
    "> - `초기값` = `Y절편(Y-intercept)` = `편향(Bias)` = $w_0$\n",
    "> - `비율` = `기울기` = `가중치(Weight)` = $w_1, w_2, \\cdots, w_k$\n",
    "\n",
    "---\n",
    "\n",
    "**1)** `방정식(Equation) = 함수(Function) = 가설(Hypothesis)`\n",
    "\n",
    "- **회귀문제:** `나이에 따라서 혈압`이 어떤 관련? / `공부 시간에 따라 성적`은 어떤 관련?\n",
    "- **가설(Hypothesis):** 머신러닝에서는 이런 `관련성을 표현한 관계식` \n",
    "\n",
    "| **종류** | **가설: $H(X)$** |\n",
    "|:---:|:---:|\n",
    "| `Multiple Linear Regression` | $$Y = w_0 + w_1 X_1 + w_2 X_2 + \\cdots + w_k X_k$$ |\n",
    "| `Simple Linear Regression` | $$Y = w_0 + w_1 X_1$$ |\n",
    "\n",
    "- **예시:** `나이에 따라서 혈압`이 어떤 관련?\n",
    "\n",
    "<center><img src='Image/Advanced/Example_LinearRegression.png' width='900'></center>\n",
    "\n",
    "$\\Rightarrow$ <span style=\"color:red\">**\"선형회귀분석은 주어진 데이터로부터 $Y \\text{와}X$의 관계를 가장 잘 나타내는 `직선을 찾는 것` 또는 `가설을 검증하는 것` 또는 `가중치와 편향을 추정하는 것`\"**</span>\n",
    "\n",
    "---\n",
    "\n",
    "**2)** `비용함수(Cost Function)`: 어떻게 `가설을 검증?` + `가중치와 편향을 추정?`\n",
    "\n",
    "- **아이디어:** 데이터를 사용하여 가설로부터 얻은 `예측값과 실제값의 차이를 최소화`하는 방향으로 `가설 또는 가중치와 편향을 업데이트`\n",
    "- **오차(Error):** 예측값과 실제값의 차이\n",
    "\n",
    "<center><img src='Image/Advanced/Cost_Function.png' width='400'>(임의 직선/가설/가중치에 따른 오차의 크기, https://wikidocs.net/21670)</center>\n",
    "\n",
    "- **오차를 반영한 관계식:** `비용함수(Cost Function) = 손실함수(Loss Function)` \n",
    "\n",
    "> - 단순히 `오차를 반영`하는 것 뿐만 아니라 `오차를 줄이는일에 최적화 된 식`\n",
    "> - 다양한 문제들마다 `적합한 비용함수들`이 있을 수 있음\n",
    "> - `회귀문제`의 경우 주로 `평균 제곱 오차(Mean Squared Error, MSE)`가 사용\n",
    ">\n",
    "> $$\n",
    "\\begin{aligned}\n",
    "\\text{Cost Function} = \\sum_{i=1}^{m} \\left[ (Y_{i} - \\sum_{j=0}^{k} w_{j}X_{j})^2 \\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    ">\n",
    "> - `오차의 크기`를 측정하기 위해 오차의 부호와 무관하도록 `제곱하여 더하여 절대적 크기 추정`\n",
    "> - 오차가 클수록 비용함수가 커지기 때문에, 결과적으로 `비용함수가 최소화되는 가중치와 편향`을 추정하면 $Y \\text{와}X$의 `관계를 가장 잘 나타내는 직선`\n",
    "\n",
    "<center><img src='Image/Advanced/Cost_Function_GDbyLine.png' width='400'></center>\n",
    "<center><img src='Image/Advanced/Cost_Function_GD.png' width='400'>(임의 직선/가설/가중치에 따른 오차의 크기 변화, https://realblack0.github.io/2020/03/27/linear-regression.html)</center>\n",
    "\n",
    "$\\Rightarrow$ <span style=\"color:red\"> **\"선형회귀분석은 주어진 데이터로부터 $Y \\text{와}X$의 관계를 가장 잘 나타내는 `가중치와 편향을 추정`하기 위해 `비용함수를 최소화` 하면 모든 데이터에 `위치적으로 가장 가까운 직선`이 추정됨\"**</span>\n",
    "\n",
    "---\n",
    "\n",
    "**3)** `옵티마이저(Optimizer)`: 어떻게 `비용함수를 최소화?`\n",
    "\n",
    "- 선형회귀분석을 포함한 `수많은 머신러닝과 딥러닝 알고리즘`은 결국 비용함수를 최소화하는 작업\n",
    "- 비용함수를 최소화 시키는 알고리즘을 `최적화 알고리즘 = 옵티마이저(Optimizer)`\n",
    "- **학습(Learning):** 데이터로 비용함수를 추정하며 `최적화 또는 옵티마이저`를 통해 적절한 `가중치와 편향`을 찾아내는 과정\n",
    "- **경사하강법(Gradient Descent):** 가장 `기본적인` 옵티마이저\n",
    "\n",
    "> - 비용함수가 `가장 최소값`을 갖게 하는 `가중치` $W$를 찾는 알고리즘\n",
    "> - 임의의 `기울기(Gradient) = 미분값` $W_0$에서 시작하여 기울기를 낮추다가 0이 될 때까지 `가중치 업데이트`하기에 `Gradient Descent`\n",
    "\n",
    "<center><img src='Image/Advanced/Cost_flow2d.png' width='500'></center>\n",
    "\n",
    "> - **수학적 추정 과정:** 틀린 초기 가중치를 `여러번 반복해서 업데이트`\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W_1 &:= W_0 - \\alpha \\frac{\\partial}{\\partial w} \\left[ \\text{Cost Function} \\right] \\\\ &= W_0 - \\alpha \\frac{\\partial C(W)}{\\partial W} |_{W=W_0} \\\\\n",
    "W_2 &:= W_1 - \\alpha \\frac{\\partial C(W)}{\\partial W} |_{W=W_1} \\\\\n",
    "W_3 &:= W_2 - \\alpha \\frac{\\partial C(W)}{\\partial W} |_{W=W_2} \\\\\n",
    "& \\vdots \\\\\n",
    "W &:= W - \\alpha \\frac{\\partial C(W)}{\\partial W}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "> - **$\\alpha$:** `가중치를 업데이트 하는 속도`로 학습률(Learning Rate)이라고 하며, 속도가 `빠르면 정확성이 낮아질` 수 있고 속도가 `느리면 오래걸리기`에 적당한 수치 필요\n",
    "\n",
    "---\n",
    "\n",
    "> **\"기울기가 `가장작은/0인 곳`을 `한번에/수학적으로` 안찾고, 왜 결국 `틀린 가중치를 여러번 반복`해서 찾으며 업데이트하나요?\"**\n",
    ">\n",
    "> - 수학적으로 `비용함수를 미분하고 0인 지점`을 찾으면 되지만 `모든 경우 가능하진 않음`\n",
    "> - 현실문제에 적합한 비용함수는 `알수가 없는 편이고 창의적인 영역` + `기울기(미분)를 꼭 계산할 수 있지 않음`\n",
    "> - 사람은 반복이 귀찮지만 컴퓨터/기계는 반복이 쉽고 `틀린 가중치를 반복적으로 업데이트하는 것`이 완벽한 정답은 아니지만 `정답에 가까운 근사치`이며 `정확성을 별도 추정`하여 신뢰도 의사결정 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c719e123d9f928ac52be215099cb039213d76cae257ca45f86a463b29cea7241"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
